{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if os.path.isdir(os.path.join(dirname, filename)):\n            print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import load_img,img_to_array\nfrom keras.utils import to_categorical\nfrom random import sample\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import f1_score,recall_score,precision_score,classification_report\nfrom sklearn.decomposition import PCA\nfrom numpy import argmax ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_shape = (150,150)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def list_files(startpath):\n    for root, dirs, files in os.walk(startpath):\n        level = root.replace(startpath, '').count(os.sep)\n        indent = ' ' * 4 * (level)\n        print('{}{}/'.format(indent, os.path.basename(root)))\n        subindent = ' ' * 4 * (level + 1)\n        for f in files:\n            if not f.endswith(\".jpg\"):\n                print('{}{}'.format(subindent, f))\n            \nlist_files(r'/kaggle/input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/identify-the-dance-form/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/identify-the-dance-form/test.csv\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ser = train_df['target'].value_counts()\nplt.figure()\nplt.bar(ser.index,ser.values,0.8)\nplt.xticks(ser.index,rotation='vertical',color='white')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_data(df,start_path,target_size):\n    df2 = df.copy()\n    for i in range(len(df)):\n        path = os.path.join(start_path,df.iloc[i,0])\n        img = load_img(path,target_size=target_size)\n        img = img_to_array(img)\n        df2.iat[i,0] = img\n    return df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_dataset(data):\n    lis = []\n    for array in data['Image']:\n        lis.append(array)\n    return np.array(lis)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_labels(train_data):\n    all_labels = list(train_data['target'].unique())\n    y = []\n    for value in train_data['target']:\n        y.append(all_labels.index(value))\n    return to_categorical(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_train_and_test_set(train_df,test_df,target_size=training_shape):\n    \n    train_data = create_data(train_df,'/kaggle/input/identify-the-dance-form/train',target_size)\n    test_data = create_data(test_df,'/kaggle/input/identify-the-dance-form/test',target_size)\n    \n    LABELS = train_data['target'].unique()\n    \n    X_train = make_dataset(train_data)/255\n    X_test = make_dataset(test_data)/255\n    y_train = make_labels(train_data)\n    \n    return X_train,y_train,X_test,LABELS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,y_train,X_test,LABELS = create_train_and_test_set(train_df,test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X_train shape : ',X_train.shape)\nprint('Y_train shape : ',y_train.shape)\nprint('X_test shape : ',X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.layers import Dense,Flatten,Dropout,Conv2D,BatchNormalization\nfrom keras.models import Model,load_model\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix\nfrom keras.optimizers import Adam\nfrom keras.metrics import accuracy\nfrom keras.callbacks import Callback,EarlyStopping,ModelCheckpoint\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pretrained_resnet_model = ResNet50(include_top = False,input_shape=training_shape+(3,),weights = 'imagenet')\nfor layer in pretrained_resnet_model.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pretrained_inceptio_model = InceptionV3(include_top = False,input_shape=training_shape+(3,),weights = 'imagenet')\nfor layer in pretrained_inceptio_model.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pretrained_inceptio_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_example(img,lael,LABELS):\n    lael = np.argmax(lael)\n    print(\"Actual label : \",LABELS[lael])\n    plt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tr,X_val,y_tr,y_val = train_test_split(X_train,y_train,test_size=0.2)\nprint(\"X_train shape : \",X_tr.shape)\nprint(\"Y_train shape : \",y_tr.shape)\nprint(\"X_val shape : \",X_val.shape)\nprint(\"Y_val shape : \",y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_fine_tune(model,lr=1e-4):\n    for layer in model.layers:\n        layer.trainable = False\n        \n    for layer in model.layers:\n        if \"BatchNormalization\" in layer.__class__.__name__:\n            layer.trainable = True\n\n    conv1 = Conv2D(filters=128,kernel_size=(2,2),padding='same',activation='relu')(model.output)\n    flatten = Flatten()(conv1)\n    dense1 = Dense(256,activation = 'relu')(flatten)\n    dropout1 = Dropout(0.3)(dense1)\n    #dense2 = Dense(32,activation = 'relu')(dropout1)\n    #dropout2 = Dropout(0.1)(dense2)\n    output = Dense(8,activation='softmax')(dropout1)\n    \n    model = Model(inputs=model.input,outputs=output)\n    model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=lr),metrics =['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model_fine_tune(pretrained_inceptio_model,lr=1e-8)\n#model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#learning rate scheduler\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(\n    lambda epoch: 1e-8 * 10**(epoch / 10))\nhistory = model.fit(X_tr,y_tr, epochs=100, callbacks=[lr_schedule],verbose=0)\nplt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\nplt.axis([1e-8, 1e-4, 0, 30])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\nplt.axis([1e-8, 1, 0, 30])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Optimal lr is 1e-3"},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = create_model_fine_tune(pretrained_inceptio_model,lr=1e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_fine_tune_partially(pretrained_model,lr=1e-3,dense=[1024],conv_filters=[256,256]):\n    for layer in pretrained_model.layers:\n        layer.trainable = False\n        \n    for layer in pretrained_model.layers:\n        if \"BatchNormalization\" in layer.__class__.__name__:\n            layer.trainable = True\n    \n    x = Conv2D(filters=256,kernel_size=(2,2),strides=1,activation='relu')(pretrained_model.get_layer('mixed5').output)\n    x = BatchNormalization()(x)\n    x = Conv2D(filters=256,kernel_size=(2,2),strides=2,activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Flatten()(x)\n    x = Dense(dense[0],activation='relu')(x)\n    x = Dropout(0.1)(x)\n    x = Dense(8,activation='softmax')(x)\n    \n    model = Model(inputs=pretrained_model.inputs,outputs=x)\n    model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=lr),metrics =['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_retrain(pretrained_model,lr=1e-3,dense=[1024]):\n    x = Conv2D(filters=256,kernel_size=(2,2),strides=1,activation='relu')(pretrained_model.get_layer('mixed5').output)\n    x = BatchNormalization()(x)\n    x = Conv2D(filters=256,kernel_size=(2,2),strides=2,activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Flatten()(x)\n    x = Dense(dense[0],activation='relu')(x)\n    x = Dropout(0.1)(x)\n    x = Dense(8,activation='softmax')(x)\n    \n    model = Model(inputs=pretrained_model.inputs,outputs=x)\n    model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=lr),metrics =['accuracy'])\n    \n    return model","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Metrics(Callback):\n    def on_train_begin(self, logs={}):\n        self.val_f1s = []\n        self.val_recalls = []\n        self.val_precisions = []\n \n    def on_epoch_end(self, epoch, logs={}):\n        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n        val_targ = self.validation_data[1]\n        _val_f1 = f1_score(val_targ, val_predict,average='weighted',zero_division=0)\n        _val_recall = recall_score(val_targ, val_predict,average='weighted',zero_division=0)\n        _val_precision = precision_score(val_targ, val_predict,average='weighted',zero_division=0)\n        self.val_f1s.append(_val_f1)\n        self.val_recalls.append(_val_recall)\n        self.val_precisions.append(_val_precision)\n        print (\" — val_f1: {:.2f} — val_precision: {:.2f} — val_recall {:.2f}\" .format(_val_f1, _val_precision, _val_recall))\n\n        return\n\nmetrics = Metrics()\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\nmc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_acc(History):\n    fig, ax = plt.subplots(2,1)\n    \n    ax[0].plot(History.history['loss'], color='b', label=\"Training loss\")\n    ax[0].plot(History.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n    \n    legend = ax[0].legend(loc='best', shadow=True)\n    ax[0].set_title('Loss')\n\n    ax[1].plot(History.history['accuracy'], color='b', label=\"Training accuracy\")\n    ax[1].plot(History.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n    legend = ax[1].legend(loc='best', shadow=True)\n    ax[1].set_title('Accuracy')\n    plt.subplots_adjust(bottom=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = classes\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        \n    fig, ax = plt.subplots(figsize=(12,6))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rotation_range=20\n                                  ,width_shift_range=0.2\n                                  ,height_shift_range=0.2\n                                  ,shear_range=0.2\n                                  ,zoom_range=0.2\n                                  ,horizontal_flip=True)\ntrain_datagen.fit(X_tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCH = 40\nBATCH_SIZE = 32\nlr = 1e-3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit\n#model.fit(X_tr,y_tr,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model_retrain(pretrained_inceptio_model,lr=lr)","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit using generator\nmodel.fit(X_tr,y_tr,epochs=1)\nhistory=model.fit_generator(train_datagen.flow(X_tr,y_tr,batch_size=BATCH_SIZE),validation_data=(X_val,y_val),epochs=EPOCH,steps_per_epoch=X_tr.shape[0]//BATCH_SIZE,verbose=2,callbacks=[metrics,es,mc])","execution_count":45,"outputs":[{"output_type":"stream","text":"Epoch 1/1\n291/291 [==============================] - 14s 47ms/step - loss: 2.0700 - accuracy: 0.3780\nEpoch 1/40\n - 4s - loss: 1.5622 - accuracy: 0.4826 - val_loss: 2.1189 - val_accuracy: 0.3699\n — val_f1: 0.34 — val_precision: 0.48 — val_recall 0.34\nEpoch 2/40\n - 2s - loss: 1.8154 - accuracy: 0.5444 - val_loss: 2.0308 - val_accuracy: 0.4384\n — val_f1: 0.39 — val_precision: 0.48 — val_recall 0.40\nEpoch 3/40\n - 3s - loss: 1.7961 - accuracy: 0.5753 - val_loss: 2.3457 - val_accuracy: 0.4932\n — val_f1: 0.44 — val_precision: 0.50 — val_recall 0.47\nEpoch 4/40\n - 2s - loss: 1.2749 - accuracy: 0.6146 - val_loss: 2.4397 - val_accuracy: 0.4932\n — val_f1: 0.41 — val_precision: 0.42 — val_recall 0.49\nEpoch 5/40\n - 2s - loss: 1.3910 - accuracy: 0.6739 - val_loss: 2.9457 - val_accuracy: 0.5068\n — val_f1: 0.43 — val_precision: 0.57 — val_recall 0.47\nEpoch 6/40\n - 2s - loss: 1.3576 - accuracy: 0.6216 - val_loss: 3.0073 - val_accuracy: 0.4658\n — val_f1: 0.42 — val_precision: 0.60 — val_recall 0.44\nEpoch 7/40\n - 2s - loss: 0.8343 - accuracy: 0.6988 - val_loss: 4.1061 - val_accuracy: 0.3973\n — val_f1: 0.30 — val_precision: 0.48 — val_recall 0.37\nEpoch 8/40\n - 2s - loss: 0.6229 - accuracy: 0.7917 - val_loss: 3.6906 - val_accuracy: 0.4521\n — val_f1: 0.42 — val_precision: 0.58 — val_recall 0.45\nEpoch 9/40\n - 2s - loss: 0.6916 - accuracy: 0.7992 - val_loss: 4.0260 - val_accuracy: 0.4658\n — val_f1: 0.43 — val_precision: 0.64 — val_recall 0.45\nEpoch 10/40\n - 2s - loss: 0.5742 - accuracy: 0.8224 - val_loss: 3.2751 - val_accuracy: 0.5342\n — val_f1: 0.45 — val_precision: 0.62 — val_recall 0.49\nEpoch 11/40\n - 2s - loss: 0.7325 - accuracy: 0.7838 - val_loss: 2.2734 - val_accuracy: 0.5753\n — val_f1: 0.54 — val_precision: 0.59 — val_recall 0.56\nEpoch 12/40\n - 2s - loss: 0.9668 - accuracy: 0.7838 - val_loss: 3.0531 - val_accuracy: 0.5342\n — val_f1: 0.50 — val_precision: 0.55 — val_recall 0.53\nEpoch 13/40\n - 2s - loss: 0.6600 - accuracy: 0.8340 - val_loss: 2.9519 - val_accuracy: 0.5890\n — val_f1: 0.55 — val_precision: 0.62 — val_recall 0.58\nEpoch 14/40\n - 2s - loss: 0.8689 - accuracy: 0.7917 - val_loss: 2.6659 - val_accuracy: 0.5616\n — val_f1: 0.53 — val_precision: 0.66 — val_recall 0.56\nEpoch 15/40\n - 2s - loss: 0.3882 - accuracy: 0.8571 - val_loss: 2.6326 - val_accuracy: 0.6027\n — val_f1: 0.56 — val_precision: 0.67 — val_recall 0.60\nEpoch 16/40\n - 1s - loss: 1.3563 - accuracy: 0.8217 - val_loss: 2.6572 - val_accuracy: 0.6164\n — val_f1: 0.60 — val_precision: 0.76 — val_recall 0.62\nEpoch 17/40\n - 2s - loss: 0.8431 - accuracy: 0.7639 - val_loss: 2.4401 - val_accuracy: 0.6301\n — val_f1: 0.65 — val_precision: 0.76 — val_recall 0.63\nEpoch 18/40\n - 2s - loss: 0.6054 - accuracy: 0.8108 - val_loss: 2.1345 - val_accuracy: 0.5616\n — val_f1: 0.59 — val_precision: 0.76 — val_recall 0.56\nEpoch 19/40\n - 2s - loss: 0.6926 - accuracy: 0.8147 - val_loss: 2.1639 - val_accuracy: 0.5753\n — val_f1: 0.56 — val_precision: 0.74 — val_recall 0.55\nEpoch 20/40\n - 2s - loss: 0.6579 - accuracy: 0.7761 - val_loss: 2.6399 - val_accuracy: 0.6438\n — val_f1: 0.63 — val_precision: 0.76 — val_recall 0.63\nEpoch 21/40\n - 2s - loss: 0.5689 - accuracy: 0.8472 - val_loss: 2.1473 - val_accuracy: 0.6849\n — val_f1: 0.69 — val_precision: 0.78 — val_recall 0.67\nEpoch 22/40\n - 2s - loss: 0.5367 - accuracy: 0.8522 - val_loss: 2.4322 - val_accuracy: 0.7123\n — val_f1: 0.71 — val_precision: 0.78 — val_recall 0.68\nEpoch 00022: early stopping\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_model('best_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train accuracy\nnp.mean(np.argmax(model.predict(X_tr),axis=1) == np.argmax(y_tr,axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#validation accuracy\nnp.mean(np.argmax(model.predict(X_val),axis=1) == np.argmax(y_val,axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_acc(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = np.argmax(model.predict(X_val),axis=1)\ny_orig = np.argmax(y_val,axis=1)\nprint(classification_report(y_orig,y_pred,target_names=LABELS))\nplot_confusion_matrix(y_orig,y_pred,LABELS,title='Confusion Matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_figures(figures, nrows = 1, ncols=1):\n    \"\"\"Plot a dictionary of figures.\n\n    Parameters\n    ----------\n    figures : <title, figure> dictionary\n    ncols : number of columns of subplots wanted in the display\n    nrows : number of rows of subplots wanted in the figure\n    \"\"\"\n\n    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows)\n    for ind,title in enumerate(figures):\n        axeslist.ravel()[ind].imshow(figures[title], cmap=plt.gray())\n        axeslist.ravel()[ind].set_title(title)\n        axeslist.ravel()[ind].set_axis_off()\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def misclassified_labels(data,pred_labels,true_labels,class1,class2,LABELS):\n    LABELS = list(LABELS)\n    class1_index = LABELS.index(class1)\n    class2_index = LABELS.index(class2)\n    print(\"Original Label : \",class1)\n    print('Predicted Label : ',class2)\n    \n    if true_labels.shape[1] == 8:\n        true_labels = np.argmax(true_labels,axis=1)\n    if pred_labels.shape[1] == 8:\n        pred_labels = np.argmax(pred_labels,axis=1)\n    \n    actual_class1_ids = np.where(true_labels==class1_index)\n    pred_class2_ids = np.where(pred_labels==class2_index)\n    \n    intersecting_ids = list(actual_class1_ids[0][np.in1d(actual_class1_ids,pred_class2_ids,assume_unique=True)])\n    if len(intersecting_ids) > 5 :\n        intersecting_ids = sample(intersecting_ids,5)\n\n    #fig,axes = plt.subplots(len(intersecting_ids))\n    #for axis,ids in zip(axes,intersecting_ids):\n    #    axis.imshow(data[ids])\n    figures = {}\n    for i in range(len(intersecting_ids)):\n        figures[str(i)] = data[intersecting_ids[i]]\n    plot_figures(figures,1,len(intersecting_ids))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"misclassified_labels(X_val,model.predict(X_val),y_val,'kathak','bharatanatyam',LABELS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_features(model,X):\n    if len(X.shape)==4:\n        return model.predict(X)\n    elif len(X.shape)==3:\n        return model.predict(X.reshape((1,X.shape[0],X.shape[1],X.shape[2])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using extracted features and svm to predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = extract_features(pretrained_resnet_model,X_tr)\ntrain_features = train_features.reshape((train_features.shape[0],train_features.shape[1]*train_features.shape[2]*train_features.shape[3]))\nval_features = extract_features(pretrained_resnet_model,X_val)\nval_features = val_features.reshape((val_features.shape[0],val_features.shape[1]*val_features.shape[2]*val_features.shape[3]))\ntest_features = extract_features(pretrained_resnet_model,X_test)\ntest_features = test_features.reshape((test_features.shape[0],test_features.shape[1]*test_features.shape[2]*test_features.shape[3]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_svm = train_features\nX_val_svm = val_features\ny_train_svm = np.argmax(y_tr,axis=1)\ny_val_svm = np.argmax(y_val,axis=1)\nX_test_svm = test_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reducing feature space\npca = PCA().fit(X_train_svm)\nX_train_svm_pca = pca.transform(X_train_svm)\nX_val_svm_pca = pca.transform(X_val_svm)\n\nprint(\"Reduced X_tr shape : \",X_train_svm_pca.shape)\nprint(\"Reduced X_val shape : \",X_val_svm_pca.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = SVC(kernel='poly',C=0.5,decision_function_shape='ovo').fit(X_train_svm,y_train_svm)\nprint(\"Train Score : \",clf.score(X_train_svm,y_train_svm))\nprint(\"Val Score : \",clf.score(X_val_svm,y_val_svm))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\ndef svc_train(X_tr,y_tr,C_=1):\n    clf = SVC(kernel='rbf',C=C_).fit(X_tr,y_tr)\n    print(\" Score : \",clf.score(X_tr,y_tr))\n    return clf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(y_val_svm,clf.predict(X_val_svm),LABELS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = clf.predict(X_val_svm)\nprint(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"misclassified_labels(X_val,test,np.argmax(y_val,axis=1),\"sattriya\",\"odissi\",LABELS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def svm_model_select(kernels=['linear', 'poly', 'rbf', 'sigmoid'],C_values=[0.4,0.7,1,3]):\n    scores = []\n    classifiers = []\n    i = 0\n    for kernel in kernels:\n        print('\\n Kernel : ',kernel)\n        for C_val in C_values:\n            i += 1\n            clf2 = SVC(kernel=kernel,C=C_val,decision_function_shape='ovo').fit(X_train_svm,y_train_svm)\n            print(\"Train Score ({}) C = {} : {:.2f}\".format(i,C_val,clf2.score(X_train_svm,y_train_svm))) \n            score = clf2.score(X_val_svm,y_val_svm)\n            print(\"Validation score : {:.2f}\".format(clf2.score(X_val_svm,y_val_svm)))\n            classifiers.append(clf2)\n    return classifiers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = svm_model_select()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_svms = svm_model_select(kernels=['linear'],C_values=[0.001,0.01,0.02,0.03,0.07,0.1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_final_soln(model,X_test,test_df,LABELS,out_file='sol.csv'):\n    temp = test_df.copy()\n    pred = model.predict(X_test)\n    if pred.shape[1] == 8 :\n        pred = argmax(pred,axis=1)\n    pred = [LABELS[i] for i in pred]\n    temp['target'] = pred\n    temp = temp.set_index(['Image'])\n    temp.head()\n    temp.to_csv(out_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_final_soln(model,X_test,test_df,LABELS,'solnn1.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_final_soln(classifiers[11],X_test_svm,test_df,LABELS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}